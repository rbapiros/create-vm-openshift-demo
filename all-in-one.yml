---
- name: Create or update Fedora VM with extra disk on OpenShift Virtualization
  hosts: localhost
  gather_facts: no
  collections:
    - kubernetes.core  # Use the kubernetes.core collection for Kubernetes modules

  vars:
    namespace: linux-vm
    vm_name: fedora-vm
    image_url: "quay.io/containerdisks/fedora:latest"
    memory: "2Gi"
    cpu_cores: 2

    disk_name: extra-disk
    disk_size: 10Gi
    storage_class: ocs-storagecluster-ceph-rbd-virtualization
    bus: virtio
    access_mode: ReadWriteOnce
    volume_mode: Filesystem

  tasks:

    # Try to retrieve the VM if it already exists.
    # This determines whether the playbook will update or create the VM.
    - name: Check if the VM already exists
      k8s_info:
        api_version: kubevirt.io/v1
        kind: VirtualMachine
        name: "{{ vm_name }}"
        namespace: "{{ namespace }}"
      register: existing_vm  # Save the result in 'existing_vm' variable for later use
      failed_when: false  # It’s okay if the VM isn’t found; we’ll create it if missing

    # Define the full spec of a brand new VM from scratch.
    # This will be used either directly (if the VM doesn’t exist), or
    # as a base to modify when applying updates like CPU, RAM, disks.
    - name: Create base VM definition
      set_fact:
        base_vm_def:
          apiVersion: kubevirt.io/v1
          kind: VirtualMachine
          metadata:
            name: "{{ vm_name }}"
            namespace: "{{ namespace }}"
          spec:
            running: true  # The VM should be running right after creation
            template:
              metadata:
                labels:
                  kubevirt.io/domain: "{{ vm_name }}"  # Label for the VM domain, used by KubeVirt
              spec:
                evictionStrategy: None  # Prevent VM eviction under node pressure
                domain:
                  cpu:
                    cores: "{{ cpu_cores }}"  # Number of CPU cores assigned
                  resources:
                    requests:
                      memory: "{{ memory }}"  # Amount of RAM assigned
                  devices:
                    disks:
                      - name: containerdisk
                        disk: { bus: virtio }  # Disk bus type for root container disk
                      - name: cloudinitdisk
                        disk: { bus: virtio }  # Disk bus type for cloud-init data disk
                volumes:
                  - name: containerdisk
                    containerDisk:
                      image: "{{ image_url }}"  # OS image to use for the VM
                  - name: cloudinitdisk
                    cloudInitNoCloud:
                      userData: |
                        #cloud-config
                        user: fedora
                        password: fedora
                        chpasswd: { expire: False }
                        ssh_pwauth: True
                        # Cloud-init config to set user and password for VM

    # When modifying CPU, RAM, or disk configuration, the VM must be stopped.
    # This only runs if the VM is already created.
    - name: Stop the VM before modifying
      when: existing_vm.resources | length > 0  # Only stop if VM exists
      k8s:
        api_version: kubevirt.io/v1
        kind: VirtualMachine
        name: "{{ vm_name }}"
        namespace: "{{ namespace }}"
        definition:
          spec:
            running: false  # Set running to false to stop the VM safely

    # VM may not stop instantly; this loop ensures the VMI is fully gone before continuing.
    # Without this wait, race conditions or API errors may occur when applying new specs.
    - name: Wait for VM to fully stop
      when: existing_vm.resources | length > 0  # Only run if VM exists
      k8s_info:
        api_version: kubevirt.io/v1
        kind: VirtualMachineInstance
        namespace: "{{ namespace }}"
        name: "{{ vm_name }}"
      register: vmi_info
      until: vmi_info.resources | length == 0  # Wait until no VM instance is running
      retries: 10  # Retry up to 10 times
      delay: 5  # Wait 5 seconds between retries
      ignore_errors: true  # Don't fail the playbook if this takes too long

    # Check if the extra disk's DataVolume already exists.
    # If it doesn't, we’ll create it in the next step.
    - name: Check if DataVolume exists
      k8s_info:
        api_version: cdi.kubevirt.io/v1beta1
        kind: DataVolume
        name: "{{ disk_name }}"
        namespace: "{{ namespace }}"
      register: dv_check
      failed_when: false  # It's okay if the DataVolume is not found (we'll create it)

    # Create a blank disk (DataVolume) for attaching as an additional virtual disk.
    # Only runs if the named disk doesn’t already exist in the namespace.
    - name: Create new DataVolume if not present
      when: dv_check.resources | length == 0  # Create only if it doesn't already exist
      k8s:
        state: present  # Ensure the DataVolume exists (create if missing)
        definition:
          apiVersion: cdi.kubevirt.io/v1beta1
          kind: DataVolume
          metadata:
            name: "{{ disk_name }}"
            namespace: "{{ namespace }}"
          spec:
            pvc:
              accessModes: ["{{ access_mode }}"]  # How the volume can be accessed (read/write)
              resources:
                requests:
                  storage: "{{ disk_size }}"  # Size of the disk requested
              volumeMode: "{{ volume_mode }}"  # Filesystem volume type
              storageClassName: "{{ storage_class }}"  # Storage backend to use
            source:
              blank: {}  # Create an empty disk, no data

    # Collect disk names from the current VM definition to detect whether the extra disk is already present.
    # This prevents duplicate entries when re-running the playbook.
    - name: Get list of existing disk names
      set_fact:
        existing_disk_names: >-
          {{
            existing_vm.resources[0].spec.template.spec.domain.devices.disks
            | map(attribute='name') | list
            if existing_vm.resources | length > 0 else []
          }}

    # Same idea as above, but for volumes instead of disks.
    # Used to make volume addition idempotent.
    - name: Get list of existing volume names
      set_fact:
        existing_volume_names: >-
          {{
            existing_vm.resources[0].spec.template.spec.volumes
            | map(attribute='name') | list
            if existing_vm.resources | length > 0 else []
          }}

    # Add the extra disk only if it's not already in the VM definition.
    # Ensures re-runs don’t break or duplicate definitions.
    - name: Build updated disk list
      set_fact:
        final_disks: >-
          {{
            (existing_vm.resources[0].spec.template.spec.domain.devices.disks
             if existing_vm.resources else base_vm_def.spec.template.spec.domain.devices.disks)
            + ([{ 'name': disk_name, 'disk': { 'bus': bus } }]
               if disk_name not in existing_disk_names else [])
          }}

    # Same logic as final_disks, but applies to volumes (which connect disks to DataVolumes).
    - name: Build updated volume list
      set_fact:
        final_volumes: >-
          {{
            (existing_vm.resources[0].spec.template.spec.volumes
             if existing_vm.resources else base_vm_def.spec.template.spec.volumes)
            + ([{ 'name': disk_name, 'dataVolume': { 'name': disk_name } }]
               if disk_name not in existing_volume_names else [])
          }}

    # Construct the full updated VM spec.
    # Includes memory, CPU, updated disk/volume lists, and the current resourceVersion.
    # This definition is eventually used in the patch request.
    - name: Build final VM definition
      set_fact:
        final_vm_def:
          apiVersion: kubevirt.io/v1
          kind: VirtualMachine
          metadata:
            name: "{{ vm_name }}"
            namespace: "{{ namespace }}"
            # Required for updating existing resources in Kubernetes.
            # If it's wrong or stale, the update will fail with a 409 Conflict.
            resourceVersion: "{{ existing_vm.resources[0].metadata.resourceVersion if existing_vm.resources else None }}"
          spec:
            running: false  # VM should remain stopped while applying config
            template:
              metadata:
                labels:
                  kubevirt.io/domain: "{{ vm_name }}"
              spec:
                evictionStrategy: None
                domain:
                  cpu:
                    cores: "{{ cpu_cores }}"
                  resources:
                    requests:
                      memory: "{{ memory }}"
                  devices:
                    disks: "{{ final_disks }}"  # Use updated disks list
                volumes: "{{ final_volumes }}"  # Use updated volumes list

    # Re-fetch the latest VM info immediately before applying changes.
    # This is crucial because the previous resourceVersion may now be outdated (if another process/operator made changes).
    # This means that the VirtualMachine resource was modified by something else (another process/operator)
    # after you fetched its definition and before you applied your changes.
    # Kubernetes will reject your update if the resourceVersion is stale to avoid overwriting concurrent changes.
    - name: Refresh VM resource version before applying
      k8s_info:
        api_version: kubevirt.io/v1
        kind: VirtualMachine
        name: "{{ vm_name }}"
        namespace: "{{ namespace }}"
      register: refreshed_vm
      failed_when: false

    # If the VM exists, overwrite the resourceVersion in our final spec with the freshest one.
    # This prevents update rejection from Kubernetes ("object has been modified").
    - name: Update resourceVersion to latest
      when: refreshed_vm.resources | length > 0
      set_fact:
        final_vm_def: >-
          {{
            final_vm_def
            | combine({
                'metadata': {
                  'resourceVersion': refreshed_vm.resources[0].metadata.resourceVersion
                }
              }, recursive=True)
          }}

    # Apply the final VM definition. This updates or creates the VM.
    # By this point, we’ve ensured no duplicates and the correct resource version.
    - name: Apply VM definition (create or update)
      k8s:
        state: present  # Ensure the resource exists with this spec
        definition: "{{ final_vm_def }}"

    # Start the VM after the new spec has been applied.
    # It was previously stopped to safely modify domain settings like CPU/memory.
    - name: Start the VM
      k8s:
        api_version: kubevirt.io/v1
        kind: VirtualMachine
        name: "{{ vm_name }}"
        namespace: "{{ namespace }}"
        definition:
          spec:
            running: true
