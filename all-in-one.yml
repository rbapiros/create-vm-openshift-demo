---
- name: Create or update Fedora VM with extra disk on OpenShift Virtualization
  hosts: localhost
  gather_facts: no
  collections:
    - kubernetes.core

  vars:
    namespace: linux-vm
    vm_name: fedora-vm
    image_url: "quay.io/containerdisks/fedora:latest"
    memory: "2Gi"
    cpu_cores: 2

    disk_name: extra-disk
    disk_size: 10Gi
    storage_class: ocs-storagecluster-ceph-rbd-virtualization
    bus: virtio
    access_mode: ReadWriteOnce
    volume_mode: Filesystem

  tasks:

    # Try to retrieve the VM if it already exists.
    # This determines whether the playbook will update or create the VM.
    - k8s_info:
        api_version: kubevirt.io/v1
        kind: VirtualMachine
        name: "{{ vm_name }}"
        namespace: "{{ namespace }}"
      register: existing_vm
      failed_when: false  # It’s okay if the VM isn’t found; we’ll create it.

    # Define the full spec of a brand new VM from scratch.
    # This will be used either directly (if the VM doesn’t exist), or
    # as a base to modify when applying updates like CPU, RAM, disks.
    - set_fact:
        base_vm_def:
          apiVersion: kubevirt.io/v1
          kind: VirtualMachine
          metadata:
            name: "{{ vm_name }}"
            namespace: "{{ namespace }}"
          spec:
            running: true  # Starts VM after creation
            template:
              metadata:
                labels:
                  kubevirt.io/domain: "{{ vm_name }}"
              spec:
                evictionStrategy: None  # Don't evict this VM under pressure
                domain:
                  cpu:
                    cores: "{{ cpu_cores }}"
                  resources:
                    requests:
                      memory: "{{ memory }}"
                  devices:
                    disks:
                      - name: containerdisk
                        disk: { bus: virtio }
                      - name: cloudinitdisk
                        disk: { bus: virtio }
                volumes:
                  - name: containerdisk
                    containerDisk:
                      image: "{{ image_url }}"
                  - name: cloudinitdisk
                    cloudInitNoCloud:
                      userData: |
                        #cloud-config
                        user: fedora
                        password: fedora
                        chpasswd: { expire: False }
                        ssh_pwauth: True

    # When modifying CPU, RAM, or disk configuration, the VM must be stopped.
    # This only runs if the VM is already created.
    - when: existing_vm.resources | length > 0
      k8s:
        api_version: kubevirt.io/v1
        kind: VirtualMachine
        name: "{{ vm_name }}"
        namespace: "{{ namespace }}"
        definition:
          spec:
            running: false

    # VM may not stop instantly; this loop ensures the VMI is fully gone before continuing.
    # Without this wait, race conditions or API errors may occur when applying new specs.
    - when: existing_vm.resources | length > 0
      k8s_info:
        api_version: kubevirt.io/v1
        kind: VirtualMachineInstance
        namespace: "{{ namespace }}"
        name: "{{ vm_name }}"
      register: vmi_info
      until: vmi_info.resources | length == 0
      retries: 10
      delay: 5
      ignore_errors: true  # Avoid total failure if cleanup is delayed

    # Check if the extra disk's DataVolume already exists.
    # If it doesn't, we’ll create it in the next step.
    - k8s_info:
        api_version: cdi.kubevirt.io/v1beta1
        kind: DataVolume
        name: "{{ disk_name }}"
        namespace: "{{ namespace }}"
      register: dv_check
      failed_when: false

    # Create a blank disk (DataVolume) for attaching as an additional virtual disk.
    # Only runs if the named disk doesn’t already exist in the namespace.
    - when: dv_check.resources | length == 0
      k8s:
        state: present
        definition:
          apiVersion: cdi.kubevirt.io/v1beta1
          kind: DataVolume
          metadata:
            name: "{{ disk_name }}"
            namespace: "{{ namespace }}"
          spec:
            pvc:
              accessModes: ["{{ access_mode }}"]
              resources:
                requests:
                  storage: "{{ disk_size }}"
              volumeMode: "{{ volume_mode }}"
              storageClassName: "{{ storage_class }}"
            source:
              blank: {}

    # Collect disk names from the current VM definition to detect whether the extra disk is already present.
    # This prevents duplicate entries when re-running the playbook.
    - set_fact:
        existing_disk_names: >-
          {{
            existing_vm.resources[0].spec.template.spec.domain.devices.disks
            | map(attribute='name') | list
            if existing_vm.resources | length > 0 else []
          }}

    # Same idea as above, but for volumes instead of disks.
    # Used to make volume addition idempotent.
    - set_fact:
        existing_volume_names: >-
          {{
            existing_vm.resources[0].spec.template.spec.volumes
            | map(attribute='name') | list
            if existing_vm.resources | length > 0 else []
          }}

    # Add the extra disk only if it's not already in the VM definition.
    # Ensures re-runs don’t break or duplicate definitions.
    - set_fact:
        final_disks: >-
          {{
            (existing_vm.resources[0].spec.template.spec.domain.devices.disks
             if existing_vm.resources else base_vm_def.spec.template.spec.domain.devices.disks)
            + ([{ 'name': disk_name, 'disk': { 'bus': bus } }]
               if disk_name not in existing_disk_names else [])
          }}

    # Same logic as final_disks, but applies to volumes (which connect disks to DataVolumes).
    - set_fact:
        final_volumes: >-
          {{
            (existing_vm.resources[0].spec.template.spec.volumes
             if existing_vm.resources else base_vm_def.spec.template.spec.volumes)
            + ([{ 'name': disk_name, 'dataVolume': { 'name': disk_name } }]
               if disk_name not in existing_volume_names else [])
          }}

    # Construct the full updated VM spec.
    # Includes memory, CPU, updated disk/volume lists, and the current resourceVersion.
    # This definition is eventually used in the patch request.
    - set_fact:
        final_vm_def:
          apiVersion: kubevirt.io/v1
          kind: VirtualMachine
          metadata:
            name: "{{ vm_name }}"
            namespace: "{{ namespace }}"
            # Required for updating existing resources in Kubernetes.
            # If it's wrong or stale, the update will fail with a 409 Conflict.
            resourceVersion: "{{ existing_vm.resources[0].metadata.resourceVersion if existing_vm.resources else None }}"
          spec:
            running: false
            template:
              metadata:
                labels:
                  kubevirt.io/domain: "{{ vm_name }}"
              spec:
                evictionStrategy: None
                domain:
                  cpu:
                    cores: "{{ cpu_cores }}"
                  resources:
                    requests:
                      memory: "{{ memory }}"
                  devices:
                    disks: "{{ final_disks }}"
                volumes: "{{ final_volumes }}"

    # Re-fetch the latest VM info immediately before applying changes.
    # This is crucial because the previous resourceVersion may now be outdated (if another process/operator made changes).
    - k8s_info:
        api_version: kubevirt.io/v1
        kind: VirtualMachine
        name: "{{ vm_name }}"
        namespace: "{{ namespace }}"
      register: refreshed_vm
      failed_when: false

    # If the VM exists, overwrite the resourceVersion in our final spec with the freshest one.
    # This prevents update rejection from Kubernetes ("object has been modified").
    - when: refreshed_vm.resources | length > 0
      set_fact:
        final_vm_def: >-
          {{
            final_vm_def
            | combine({
                'metadata': {
                  'resourceVersion': refreshed_vm.resources[0].metadata.resourceVersion
                }
              }, recursive=True)
          }}

    # Apply the final VM definition. This updates or creates the VM.
    # By this point, we’ve ensured no duplicates and the correct resource version.
    - k8s:
        state: present
        definition: "{{ final_vm_def }}"

    # Start the VM after the new spec has been applied.
    # It was previously stopped to safely modify domain settings like CPU/memory.
    - k8s:
        api_version: kubevirt.io/v1
        kind: VirtualMachine
        name: "{{ vm_name }}"
        namespace: "{{ namespace }}"
        definition:
          spec:
            running: true
